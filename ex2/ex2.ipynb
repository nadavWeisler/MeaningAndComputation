{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\Users\\yelfs\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "done1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "print(\"done1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done2\n"
     ]
    }
   ],
   "source": [
    "# Exports data from corpus\n",
    "sentences, cur_sent = list(), list()\n",
    "with open('./wackypedia_en1.words10.20Mwords') as f:\n",
    " for line in f:\n",
    "    line = line.strip()\n",
    "    if line == '</s>':\n",
    "        sentences.append(cur_sent)\n",
    "        cur_sent = list()\n",
    "    elif line != '<s>' and not line.startswith('<text') and not line.startswith('</text'):\n",
    "        cur_sent.append(line.split('\\t')[0])\n",
    "print(\"done2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done3\n"
     ]
    }
   ],
   "source": [
    "# Builds the models\n",
    "model_big_ten = gensim.models.Word2Vec(sentences, min_count=5, window=1, vector_size=10)\n",
    "model_small_ten = gensim.models.Word2Vec(sentences, min_count=5, window=10, vector_size=10)\n",
    "\n",
    "model_big_five = gensim.models.Word2Vec(sentences, min_count=5, window=1, vector_size=500)\n",
    "model_small_five = gensim.models.Word2Vec(sentences, min_count=5, window=10, vector_size=500)\n",
    "\n",
    "models = [model_big_ten, model_small_ten, model_big_five, model_small_five]\n",
    "print(\"done3\")"
   ]
  },
  {
   "source": [
    "\n",
    "# Makes the similarity lists\n",
    "words = pd.read_csv('./SimLex-999/SimLex-999.txt', delimiter='\\t')\n",
    "pairs = list(zip(words['word1'],words['word2']))\n",
    "print(\"done4\")"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done4\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# Calculate similarity and write to files\n",
    "results = [[], [], [], []]\n",
    "pos = words['POS']\n",
    "models_data = [\"size10_window1\", \"size10_window10\", \"size500_window1\", \"size500_window10\"]\n",
    "for j in range(len(models)):\n",
    "    f = open(models_data[j],\"w+\")\n",
    "    for i in range(len(pairs)):\n",
    "        try:\n",
    "            similarity = models[j].wv.similarity(pairs[i][0], pairs[i][1])\n",
    "        except KeyError:\n",
    "            similarity = 0\n",
    "        finally:\n",
    "            results[j].append(similarity)\n",
    "            f.write(pairs[i][0] + \"\\t\" + pairs[i][1] + \"\\t\" + pos[i] + \"\\t\" + str(similarity) + \"\\n\")\n",
    "print(\"done5\")"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done5\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[SpearmanrResult(correlation=0.1267090606417617, pvalue=5.9176296353660535e-05), SpearmanrResult(correlation=0.2020214109355799, pvalue=1.164863083951351e-10), SpearmanrResult(correlation=0.2141625662511345, pvalue=7.915633078730475e-12), SpearmanrResult(correlation=0.23801322524877044, pvalue=2.4732725873936907e-14)]\n"
     ]
    }
   ],
   "source": [
    "# Calculate overall correlation\n",
    "cor_results = []\n",
    "golden_sim = words['SimLex999']\n",
    "for result in results:\n",
    "    sim_res = sp.stats.spearmanr(result, golden_sim)\n",
    "    cor_results.append(sim_res)\n",
    "print(cor_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.12232063598153842, 0.22873673735132238, 0.20493154689075563, 0.23527904302198654]\n"
     ]
    }
   ],
   "source": [
    "# Get noun correleation\n",
    "pos = words['POS']\n",
    "n_results = [[], [], [], []]\n",
    "\n",
    "for j in range(len(models)):\n",
    "    for i in range(len(pairs)):\n",
    "        if pos[i] == 'N':\n",
    "            try:\n",
    "                similarity = models[j].wv.similarity(pairs[i][0], pairs[i][1])\n",
    "            except KeyError:\n",
    "                similarity = 0\n",
    "            finally:\n",
    "                n_results[j].append(similarity)\n",
    "\n",
    "n_golden = []\n",
    "for i in range(len(pairs)):\n",
    "    if pos[i] == 'N':\n",
    "        n_golden.append(words['SimLex999'][i])\n",
    "\n",
    "n_cor_results = []\n",
    "\n",
    "for result in n_results:\n",
    "    sim_res, pval = sp.stats.spearmanr(result, n_golden)\n",
    "    n_cor_results.append(sim_res)\n",
    "print(n_cor_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.21273823069807435, 0.22319436475783655, 0.3089627459857727, 0.27468084275080756]\n"
     ]
    }
   ],
   "source": [
    "# Get adjective correlation\n",
    "pos = words['POS']\n",
    "n_results = [[], [], [], []]\n",
    "\n",
    "for j in range(len(models)):\n",
    "    for i in range(len(pairs)):\n",
    "        if pos[i] == 'A':\n",
    "            try:\n",
    "                similarity = models[j].wv.similarity(pairs[i][0], pairs[i][1])\n",
    "            except KeyError:\n",
    "                similarity = 0\n",
    "            finally:\n",
    "                n_results[j].append(similarity)\n",
    "\n",
    "n_golden = []\n",
    "for i in range(len(pairs)):\n",
    "    if pos[i] == 'A':\n",
    "        n_golden.append(words['SimLex999'][i])\n",
    "\n",
    "n_cor_results = []\n",
    "\n",
    "for result in n_results:\n",
    "    sim_res, pval = sp.stats.spearmanr(result, n_golden)\n",
    "    n_cor_results.append(sim_res)\n",
    "print(n_cor_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.08472524350619494, 0.10564962010490918, 0.22658587000780966, 0.21715141881979055]\n"
     ]
    }
   ],
   "source": [
    "# get verbs correlation\n",
    "pos = words['POS']\n",
    "n_results = [[], [], [], []]\n",
    "\n",
    "for j in range(len(models)):\n",
    "    for i in range(len(pairs)):\n",
    "        if pos[i] == 'V':\n",
    "            try:\n",
    "                similarity = models[j].wv.similarity(pairs[i][0], pairs[i][1])\n",
    "            except KeyError:\n",
    "                similarity = 0\n",
    "            finally:\n",
    "                n_results[j].append(similarity)\n",
    "\n",
    "n_golden = []\n",
    "for i in range(len(pairs)):\n",
    "    if pos[i] == 'V':\n",
    "        n_golden.append(words['SimLex999'][i])\n",
    "\n",
    "n_cor_results = []\n",
    "\n",
    "for result in n_results:\n",
    "    sim_res, pval = sp.stats.spearmanr(result, n_golden)\n",
    "    n_cor_results.append(sim_res)\n",
    "print(n_cor_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------\nsize10_window1 RESULTS\n--------------------------------\n[[('widow', 0.9832034707069397), ('brother', 0.9827520251274109), ('son', 0.9822415113449097), ('cousin', 0.9805023074150085), ('nephew', 0.978701651096344), ('daughter', 0.97786545753479), ('grandmother', 0.9726814031600952), ('uncle', 0.9720106720924377), ('grandfather', 0.9687551856040955), ('niece', 0.9683469533920288)]]\n--------------------------------\nsize10_window10 RESULTS\n--------------------------------\n[[('married', 0.9673024415969849), ('sister', 0.960009753704071), ('Troy', 0.9545236825942993), ('Catherine', 0.9468388557434082), ('Titus', 0.9466161131858826), ('brother', 0.9464559555053711), ('Anne', 0.9455770254135132), ('murdered', 0.9450943470001221), ('daughter', 0.9438880085945129), ('Alfonso', 0.9417060017585754)]]\n--------------------------------\nsize500_window1 RESULTS\n--------------------------------\n[[('widow', 0.6843394637107849), ('girlfriend', 0.6738806366920471), ('niece', 0.6689202785491943), ('grandmother', 0.6626967191696167), ('uncle', 0.6589571237564087), ('granddaughter', 0.658128023147583), ('consort', 0.6576066613197327), ('cousin', 0.6572809219360352), ('brother', 0.6457736492156982), ('aunt', 0.6361069679260254)]]\n--------------------------------\nsize500_window10 RESULTS\n--------------------------------\n[[('daughter', 0.7471644878387451), ('sister', 0.7469867467880249), ('cousin', 0.7101747989654541), ('aunt', 0.708203911781311), ('grandmother', 0.7029860019683838), ('brother', 0.6992103457450867), ('widow', 0.6991974711418152), ('Anna', 0.6982079148292542), ('niece', 0.6899842023849487), ('son', 0.685929536819458)]]\n"
     ]
    }
   ],
   "source": [
    "# Print analogy by model\n",
    "\n",
    "for index, model in enumerate(models):\n",
    "    results = []\n",
    "    print(\"--------------------------------\")\n",
    "    print(models_data[index] + \" RESULTS\")\n",
    "    print(\"--------------------------------\")\n",
    "    results.append(model.wv.most_similar(positive=['dog', 'wife'], negative=['cat']))\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------\nsize10_window1 RESULTS\n--------------------------------\n[[('rise', 0.9800962209701538), ('forward', 0.9667182564735413), ('up', 0.9434640407562256), ('refuge', 0.9377111196517944), ('westward', 0.9349880814552307), ('ban', 0.933565080165863), ('out', 0.9298392534255981), ('back', 0.9286207556724548), ('possession', 0.9285981059074402), ('suit', 0.9278940558433533)]]\n--------------------------------\nsize10_window10 RESULTS\n--------------------------------\n[[('able', 0.9443411231040955), ('force', 0.9265884160995483), ('removed', 0.8982120752334595), ('passing', 0.8868582248687744), ('ready', 0.8801742792129517), ('allowed', 0.8768723011016846), ('charge', 0.874687910079956), ('pressed', 0.8739463686943054), ('order', 0.8736936450004578), ('required', 0.8671567440032959)]]\n--------------------------------\nsize500_window1 RESULTS\n--------------------------------\n[[('freedom', 0.47313764691352844), ('advance', 0.46372777223587036), ('force', 0.4615896940231323), ('command', 0.4491076171398163), ('responsibility', 0.4483332931995392), ('arm', 0.4467941224575043), ('permission', 0.44015058875083923), ('throne', 0.4326472282409668), ('opportunity', 0.430109441280365), ('allegiance', 0.4299171566963196)]]\n--------------------------------\nsize500_window10 RESULTS\n--------------------------------\n[[('receiver', 0.4944068491458893), ('position', 0.49410852789878845), ('observer', 0.4526493549346924), ('check', 0.4496242105960846), ('authority', 0.4480673670768738), ('freedom', 0.445950984954834), ('forward', 0.4458613395690918), ('force', 0.4395013749599457), ('register', 0.4354192614555359), ('direction', 0.4338468015193939)]]\n"
     ]
    }
   ],
   "source": [
    "# Print analogy by model\n",
    "for index, model in enumerate(models):\n",
    "    results = []\n",
    "    print(\"--------------------------------\")\n",
    "    print(models_data[index] + \" RESULTS\")\n",
    "    print(\"--------------------------------\")\n",
    "    results.append(model.wv.most_similar(positive=['light', 'right'], negative=['dark']))\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------\nsize10_window1 RESULTS\n--------------------------------\n[[('difficulty', 0.9592686891555786), ('patient', 0.9415267109870911), ('possibility', 0.9373559951782227), ('truly', 0.9363977909088135), ('increasingly', 0.9333330988883972), ('seemingly', 0.9332449436187744), ('crime', 0.930452823638916), ('incapable', 0.9296925067901611), ('situation', 0.9232394099235535), ('best', 0.9209893941879272)]]\n--------------------------------\nsize10_window10 RESULTS\n--------------------------------\n[[('copyright', 0.9511670470237732), ('motivation', 0.9128372073173523), ('examination', 0.9108969569206238), ('appeal', 0.9087449312210083), ('action', 0.9044215679168701), ('inquiry', 0.8968518376350403), ('decisions', 0.8849015235900879), ('procedure', 0.8809605836868286), ('defendant', 0.8809313178062439), ('credibility', 0.877590000629425)]]\n--------------------------------\nsize500_window1 RESULTS\n--------------------------------\n[[('person', 0.47325262427330017), ('woman', 0.441050261259079), ('defendant', 0.4404895603656769), ('child', 0.42332902550697327), ('truly', 0.4185948073863983), ('voter', 0.4109712839126587), ('witness', 0.41036418080329895), ('patient', 0.40872958302497864), ('thing', 0.4008568823337555), ('foal', 0.40062829852104187)]]\n--------------------------------\nsize500_window10 RESULTS\n--------------------------------\n[[('reward', 0.4730565845966339), ('necessity', 0.44398054480552673), ('humanity', 0.43857866525650024), ('promise', 0.43535172939300537), ('God', 0.43158620595932007), ('himself', 0.41627106070518494), ('desire', 0.41131672263145447), ('determination', 0.4102616012096405), ('gesture', 0.40169572830200195), ('person', 0.40020763874053955)]]\n"
     ]
    }
   ],
   "source": [
    "# Print analogy by model\n",
    "for index, model in enumerate(models):\n",
    "    results = []\n",
    "    print(\"--------------------------------\")\n",
    "    print(models_data[index] + \" RESULTS\")\n",
    "    print(\"--------------------------------\")\n",
    "    results.append(model.wv.most_similar(positive=['new', 'man'], negative=['old']))\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------\nsize10_window1 RESULTS\n--------------------------------\n[[('prosperous', 0.9776113629341125), ('consuming', 0.9714850783348083), ('productive', 0.962975025177002), ('breeding', 0.9611977338790894), ('regular', 0.9564952254295349), ('distant', 0.9551976919174194), ('lean', 0.9528768062591553), ('active', 0.952736496925354), ('respectable', 0.9509806632995605), ('favourable', 0.9458457827568054)]]\n--------------------------------\nsize10_window10 RESULTS\n--------------------------------\n[[('eight', 0.9217930436134338), ('six', 0.9133078455924988), ('four', 0.9059357047080994), ('five', 0.8998093605041504), ('top', 0.8926584720611572), ('ten', 0.8908166289329529), ('golf', 0.8779656887054443), ('regular', 0.8765390515327454), ('Gator', 0.8669626116752625), ('tennis', 0.8603619337081909)]]\n--------------------------------\nsize500_window1 RESULTS\n--------------------------------\n[[('bright', 0.6023468375205994), ('busy', 0.581092119216919), ('fine', 0.5800844430923462), ('tall', 0.5606681704521179), ('tough', 0.5503038763999939), ('tiny', 0.5497660636901855), ('green', 0.5467810034751892), ('dirty', 0.5457372069358826), ('vicious', 0.543742299079895), ('gigantic', 0.5426762700080872)]]\n--------------------------------\nsize500_window10 RESULTS\n--------------------------------\n[[('huge', 0.5501598715782166), ('busy', 0.5226951241493225), ('tough', 0.5183656215667725), ('tight', 0.49854084849357605), ('carpet', 0.49656593799591064), ('climbing', 0.4846390187740326), ('pants', 0.48397594690322876), ('lush', 0.4838052988052368), ('shirt', 0.4810762107372284), ('racing', 0.4803398549556732)]]\n"
     ]
    }
   ],
   "source": [
    "# Print analogy by model\n",
    "for index, model in enumerate(models):\n",
    "    results = []\n",
    "    print(\"--------------------------------\")\n",
    "    print(models_data[index] + \" RESULTS\")\n",
    "    print(\"--------------------------------\")\n",
    "    results.append(model.wv.most_similar(positive=['white', 'big'], negative=['black']))\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------\nsize10_window1 RESULTS\n--------------------------------\n[[('down', 0.9800690412521362), ('away', 0.977653980255127), ('storm', 0.9719418883323669), ('off', 0.9693686962127686), ('out', 0.9658371806144714), ('apart', 0.9584853053092957), ('steadily', 0.9568665623664856), ('tickets', 0.9446605443954468), ('back', 0.9410886168479919), ('rapidly', 0.9394614696502686)]]\n--------------------------------\nsize10_window10 RESULTS\n--------------------------------\n[[('off', 0.8984220623970032), ('away', 0.8631198406219482), ('back', 0.8602479696273804), ('household', 0.8543658256530762), ('down', 0.8539766669273376), ('out', 0.8521571159362793), ('caught', 0.8473911285400391), ('remaining', 0.8438048958778381), ('rushing', 0.8331202268600464), ('traveling', 0.8278323411941528)]]\n--------------------------------\nsize500_window1 RESULTS\n--------------------------------\n[[('off', 0.5624390244483948), ('down', 0.5223851203918457), ('forth', 0.5061142444610596), ('aside', 0.49612143635749817), ('apart', 0.4830143451690674), ('together', 0.4674402177333832), ('sail', 0.4482267498970032), ('forward', 0.4410666227340698), ('ashore', 0.4358993172645569), ('foot', 0.4258604943752289)]]\n--------------------------------\nsize500_window10 RESULTS\n--------------------------------\n[[('aside', 0.49453991651535034), ('off', 0.48314526677131653), ('down', 0.46312063932418823), ('sail', 0.4434621334075928), ('feet', 0.401530921459198), ('ablaze', 0.398215651512146), ('apart', 0.37059178948402405), ('heads', 0.36623480916023254), ('tall', 0.3633204996585846), ('caps', 0.3614109456539154)]]\n"
     ]
    }
   ],
   "source": [
    "# Print analogy by model\n",
    "for index, model in enumerate(models):\n",
    "    results = []\n",
    "    print(\"--------------------------------\")\n",
    "    print(models_data[index] + \" RESULTS\")\n",
    "    print(\"--------------------------------\")\n",
    "    results.append(model.wv.most_similar(positive=['white', 'up'], negative=['black']))\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python368jvsc74a57bd0b1411b1b95c1bf0479e3d7cdc7e102371516c7735698e266ce38042d8c148f2e",
   "display_name": "Python 3.6.8 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}