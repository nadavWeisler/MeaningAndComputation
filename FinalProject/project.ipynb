{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Meaning & Computation - Final Project"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "import pandas as pd\r\n",
    "import gensim\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import stop-words"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "## Base Run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Prepare data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import data csv's to Pandas data-frame"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "all_data = pd.read_csv(\"./data/Emotion_final.csv\")\r\n",
    "andbrain_data =pd.read_csv(\"./data/Andbrain_DataSet.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Shuffle data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "shuffled_data = all_data.sample(frac=1).reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Divide in to train & test "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "y = shuffled_data[\"label\"]\r\n",
    "x = shuffled_data\r\n",
    "\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(\r\n",
    "    x, y, test_size=0.2, random_state=42)\r\n",
    "\r\n",
    "y_train = y_train.to_frame()\r\n",
    "y_test = y_test.to_frame()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create algorithms list"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "algorithms = [LogisticRegression()]\r\n",
    "#algorithms = [LogisticRegression(), RandomForestClassifier(), SGDClassifier()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create and fit count vectorizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "count_vectorizer=CountVectorizer(analyzer='word', ngram_range=(1, 1))\r\n",
    "x = count_vectorizer.fit_transform(x_train[\"text\"])\r\n",
    "print(x.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15854, 16304)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calculate accuracy of data function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def calculate_accuracy(predicted_data):\r\n",
    "    count_equals = 0\r\n",
    "    for idx, (_, row) in enumerate(x_test.iterrows()):\r\n",
    "        if row[\"label\"] == predicted_data[idx]:\r\n",
    "            count_equals += 1\r\n",
    "    print(f\"accuracy={count_equals/len(predicted_data)}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get confusion matrix of predictions data-frame function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def get_confusion_matrix(predictions):\r\n",
    "    matrix = np.zeros(25).reshape(5, 5)\r\n",
    "\r\n",
    "    for a,b in zip(predictions, x_test.label):\r\n",
    "        matrix[emotions[a]][emotions[b]] += 1\r\n",
    "        \r\n",
    "    print(matrix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get sentences function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def get_sentences(true_label, predicted_label, num_of_results, predictions, test_collection):\r\n",
    "  counter = 0\r\n",
    "  for i, (a, b) in enumerate(zip (test_collection.label, predictions)):\r\n",
    "    if counter == num_of_results:\r\n",
    "      break\r\n",
    "    if a == true_label and b == predicted_label:\r\n",
    "      print(test_collection.iloc[[i]][\"text\"].values)\r\n",
    "      counter += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get strongest words function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def get_strongest_words(label, pipe, count_vectorizer):\r\n",
    "    inverse_dict={count_vectorizer.vocabulary_[w]:w for w in count_vectorizer.vocabulary_.keys()}\r\n",
    "    cur_coef=pipe[\"algo\"].coef_[emotions[label]]\r\n",
    "    word_df=pd.DataFrame({\"val\":cur_coef}).reset_index().sort_values([\"val\"],ascending=[False])\r\n",
    "    word_df.loc[:, \"word\"]=word_df[\"index\"].apply(lambda v:inverse_dict[v])\r\n",
    "    print(word_df.head(10))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Base"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "for algorithm_under_test in algorithms:\r\n",
    "    pipe = Pipeline([('vectorizer', count_vectorizer),\r\n",
    "                    ('algo', algorithm_under_test)])\r\n",
    "    pipe.fit(x_train[\"text\"], y_train[\"label\"])\r\n",
    "    predicted = pipe.predict(x_test[\"text\"])\r\n",
    "    calculate_accuracy(predicted)\r\n",
    "    try:\r\n",
    "        get_strongest_words('happy', pipe, count_vectorizer)\r\n",
    "    except AttributeError:\r\n",
    "        pass\r\n",
    "    get_confusion_matrix(predicted)\r\n",
    "    get_sentences('happy', 'sadness', 3, predicted, x_test)\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\t-nweisler\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy=0.908678102926337\n",
      "       index       val         word\n",
      "12404  12404  2.714255    satisfied\n",
      "13999  13999  2.551725     superior\n",
      "11945  11945  2.547231     resolved\n",
      "2984    2984  2.493536    contented\n",
      "12973  12973  2.474030      sincere\n",
      "4496    4496  2.466922     ecstatic\n",
      "11954  11954  2.466773    respected\n",
      "3043    3043  2.460642    convinced\n",
      "10738  10738  2.447442      pleased\n",
      "278      278  2.428949  adventurous\n",
      "[[ 480.   17.   11.   21.    3.]\n",
      " [  13.  466.    9.   23.   33.]\n",
      " [  28.   17. 1346.   33.   21.]\n",
      " [  41.   29.   28. 1196.    8.]\n",
      " [   0.   14.    6.    7.  114.]]\n",
      "['i lost him i realized that i really didnt have anything to fear and that in reality he was the one person that was helping me to trust again because i would tell him how i felt and he would give me back the same and it was starting to feel safe']\n",
      "['i feel sure the donation would have been rejected']\n",
      "['But now she looked exci']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Read wikipedia data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "train_data_list, cur_sent = list(), list()\r\n",
    "with open('./data/wackypedia_en1.words10.20Mwords') as f:\r\n",
    " for line in f:\r\n",
    "    line = line.strip()\r\n",
    "    if line == '</s>':\r\n",
    "        train_data_list.append(cur_sent)\r\n",
    "        cur_sent = list()\r\n",
    "    elif line != '<s>' and not line.startswith('<text') and not line.startswith('</text'):\r\n",
    "        cur_sent.append(line.split('\\t')[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create model using word2Vec"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "word2vec_model = gensim.models.Word2Vec(\r\n",
    "    train_data_list, min_count=5, window=10, vector_size=500)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Filter stopwords from sentences"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def get_without_stopwords(sentence):\r\n",
    "\tword_tokens = word_tokenize(sentence)\r\n",
    " \r\n",
    "\tfiltered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\r\n",
    "\t\r\n",
    "\tfiltered_sentence = []\r\n",
    "\t\r\n",
    "\tfor w in word_tokens:\r\n",
    "\t\tif w not in stop_words:\r\n",
    "\t\t\tfiltered_sentence.append(w)\r\n",
    "\treturn filtered_sentence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create emotions dictionary"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "emotions = dict()\r\n",
    "emotions[\"anger\"] = 0\r\n",
    "emotions[\"fear\"] = 1\r\n",
    "emotions[\"happy\"] = 2\r\n",
    "emotions[\"sadness\"] = 3\r\n",
    "emotions[\"surprise\"] = 4"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get word score function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "def get_word_score(word):\r\n",
    "\tscores = [0, 0, 0, 0, 0]\r\n",
    "\tsimilar_words = word2vec_model.wv.most_similar(word)[:3]\r\n",
    "\tsimilar_words.append((word, 1.0))\r\n",
    "\tfor word_candidate in similar_words:\r\n",
    "\t\ttry:\r\n",
    "\t\t\tword_score_row = andbrain_data.loc[andbrain_data['word'] == word_candidate[0] + \" \"]\r\n",
    "\t\t\tif not word_score_row.empty:\r\n",
    "\t\t\t\tcolumns = list(word_score_row)\r\n",
    "\t\t\t\tfor column in columns:\r\n",
    "\t\t\t\t\tif column != 'word':\r\n",
    "\t\t\t\t\t\tscores[emotions[column]] += word_score_row[column].values[0]\r\n",
    "\t\texcept KeyError as e:\r\n",
    "\t\t\tcontinue\r\n",
    "\treturn scores\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Function that get if all emotions are equal to zero"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "def is_all_emotions_zero(word_score):\r\n",
    "\tfor score in word_score:\r\n",
    "\t\tif score != 0:\r\n",
    "\t\t\treturn False\r\n",
    "\treturn True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get sentence score function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "def get_sentence_score(word_tokens):\r\n",
    "\tsentence_score = [0, 0, 0, 0, 0]\r\n",
    "\tfor word in word_tokens:\r\n",
    "\t\ttry:\r\n",
    "\t\t\tword_score = get_word_score(word)\r\n",
    "\t\t\tif not is_all_emotions_zero(word_score):\r\n",
    "\t\t\t\tsentence_score[word_score.index(max(word_score))] += 1\r\n",
    "\t\texcept KeyError:\r\n",
    "\t\t\tpass\r\n",
    "\treturn sentence_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get score for raw sentence function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def get_score(raw_sentence):\r\n",
    "\tnon_stopwords = get_without_stopwords(raw_sentence)\r\n",
    "\tsentence_score = np.array(get_sentence_score(non_stopwords))\r\n",
    "\treturn sentence_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get sentence with score tokens function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def get_sentence_with_score_tokens(sentence, score):\r\n",
    "\tfor emotion in emotions.keys():\r\n",
    "\t\tfor i in range(score[emotions[emotion]]):\r\n",
    "\t\t\tsentence += \" #\" + emotion\r\n",
    "\treturn sentence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get process data function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "def get_processed_data(data_to_process):\r\n",
    "\tprocessed_data = pd.DataFrame(columns=data_to_process.columns)\r\n",
    "\tfor idx, (_, row) in enumerate(data_to_process.iterrows()):\r\n",
    "\t\tprint(str(idx) + \" OUT OF \" + str(data_to_process.shape[0]))\r\n",
    "\t\traw_sentence = row[\"text\"]\r\n",
    "\t\tsentence_score = get_score(raw_sentence)\r\n",
    "\t\tsentence_with_score = get_sentence_with_score_tokens(raw_sentence, sentence_score)\r\n",
    "\t\tdata_to_add = {'text': str(sentence_with_score), 'label': row[\"label\"]}\r\n",
    "\t\tprocessed_data = processed_data.append(data_to_add, ignore_index=True)\r\n",
    "\treturn processed_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run Experiment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get processed train and test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "processed_train = get_processed_data(x_train)\r\n",
    "processed_test = get_processed_data(x_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 OUT OF 15854\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "can only concatenate tuple (not \"str\") to tuple",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-40c05a5a9459>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprocessed_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_processed_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprocessed_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_processed_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-24d42fec2c44>\u001b[0m in \u001b[0;36mget_processed_data\u001b[1;34m(data_to_process)\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" OUT OF \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_process\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mraw_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                 \u001b[0msentence_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                 \u001b[0msentence_with_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sentence_with_score_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_sentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                 \u001b[0mdata_to_add\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_with_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-abe9555921ce>\u001b[0m in \u001b[0;36mget_score\u001b[1;34m(raw_sentence)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[0mnon_stopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_without_stopwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0msentence_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_sentence_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_stopwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msentence_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-c0a2e60ac306>\u001b[0m in \u001b[0;36mget_sentence_score\u001b[1;34m(word_tokens)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_tokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                         \u001b[0mword_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_word_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_all_emotions_zero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                 \u001b[0msentence_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-e62a92cfc868>\u001b[0m in \u001b[0;36mget_word_score\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword_candidate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msimilar_words\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                         \u001b[0mword_score_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mandbrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mandbrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mword_candidate\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword_score_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                 \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_score_row\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate tuple (not \"str\") to tuple"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get process train data with only the meaning tags"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "processed_train_filtered = processed_train.copy()\r\n",
    "for idx, (_, row) in enumerate(processed_train_filtered.iterrows()):\r\n",
    "\tif '#' in row[\"text\"]:\r\n",
    "\t\trow[\"text\"] = row[\"text\"][row[\"text\"].find(\"#\"):]\r\n",
    "print(processed_train_filtered.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                    text    label\n",
      "0                                  #fear #fear #surprise     fear\n",
      "1      #happy #happy #happy #happy #happy #sadness #a...  sadness\n",
      "2               #happy #happy #happy #anger #anger #fear    happy\n",
      "3              #happy #sadness #fear #surprise #surprise    happy\n",
      "4                   i feel weird a href http bondmusings     fear\n",
      "...                                                  ...      ...\n",
      "15849                   i feel like im a gorgeous person    happy\n",
      "15850                               #happy #happy #happy    happy\n",
      "15851        i feel like i have been rather unkind to it    anger\n",
      "15852  im sure everyone is starting to feel the chris...    happy\n",
      "15853                #happy #sadness #surprise #surprise     fear\n",
      "\n",
      "[15854 rows x 2 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get process test data with only the meaning tags"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "processed_test_filtered = processed_test.copy()\r\n",
    "for idx, (_, row) in enumerate(processed_test_filtered.iterrows()):\r\n",
    "\tif '#' in row[\"text\"]:\r\n",
    "\t\trow[\"text\"] = row[\"text\"][row[\"text\"].find(\"#\"):]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vectorized processed data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count_vectorizer_processed=CountVectorizer(analyzer='word', ngram_range=(1, 1))\r\n",
    "vectors = count_vectorizer_processed.fit_transform(processed_train_filtered[\"text\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Run pipeline using the precessed data after the change"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for algorithm_under_test in algorithms:\r\n",
    "    pipe = Pipeline([('vectorizer', count_vectorizer_processed),\r\n",
    "                    ('algo', algorithm_under_test)])\r\n",
    "    pipe.fit(processed_train_filtered[\"text\"], y_train[\"label\"])\r\n",
    "    predicted = pipe.predict(processed_test_filtered[\"text\"])\r\n",
    "    calculate_accuracy(predicted)\r\n",
    "    try:\r\n",
    "        get_strongest_words('happy', pipe, count_vectorizer_processed)\r\n",
    "    except AttributeError:\r\n",
    "        pass\r\n",
    "    get_confusion_matrix(predicted)\r\n",
    "    get_sentences('happy', 'sadness', 5, predicted, processed_test_filtered)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\Users\\yelfs\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy=0.42658930373360243\n",
      "      index       val         word\n",
      "1758   1758  1.803762     talented\n",
      "1859   1859  1.733294   triumphant\n",
      "339     339  1.720999      content\n",
      "971     971  1.696127  invigorated\n",
      "316     316  1.568278   complacent\n",
      "1413   1413  1.550632   productive\n",
      "12       12  1.486480     accepted\n",
      "556     556  1.454419     ecstatic\n",
      "1492   1492  1.448381    respected\n",
      "871     871  1.397202      honored\n",
      "[[ 51.   3.   3.   3.   1.]\n",
      " [  3.  28.   1.   1.   4.]\n",
      " [280. 248. 995. 616.  94.]\n",
      " [267. 229. 435. 614.  79.]\n",
      " [  0.   5.   1.   0.   3.]]\n",
      "['#fear #fear #surprise']\n",
      "['#happy #sadness #sadness #sadness #anger #fear #surprise #surprise']\n",
      "['#sadness']\n",
      "['#sadness #sadness #fear #fear #surprise #surprise #surprise']\n",
      "['#happy #sadness #fear #fear #surprise #surprise #surprise #surprise #surprise #surprise']\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "5e49d1d782d0c81664cfef69a5a300da04b0c8dd1f7059897730ec0e8bf9da48"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}